<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>我的博客</title><link>https://blog.poneding.com/aws/</link><description>Recent content on 我的博客</description><generator>Hugo</generator><language>cn</language><atom:link href="https://blog.poneding.com/aws/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://blog.poneding.com/aws/build-eks-cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/build-eks-cluster/</guid><description>我的博客 / AWS / 搭建EKS集群
搭建EKS集群 # 安装aws，kubectl和eksctl命令行工具 # 引言 # 安装aws cli 安装kubectl cli 安装eksctl cli 安装aws cli # 参考 # https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/cli-chap-install.html
安装示例（windows） # 下载安装包： https://awscli.amazonaws.com/AWSCLIV2.msi 运行下载的安装包 确实安装是否成功 aws --version 使用Security Credentials配置aws cli # 访问aws控制台：Service =&amp;gt; IAM 选择IAM User，使用子用户，强烈不建议使用root用户 进入用户详情页面，Security Credentials页 创建Access Key 拷贝Access Key ID和Secret Access Key 使用aws命令配置 $ aws configure AWS Access Key ID [None]: ABCDEFGHIAZBERTUCNGG (替换Access Key ID) AWS Secret Access Key [None]: uMe7fumK1IdDB094q2sGFhM5Bqt3HQRw3IHZzBDTm (替换Secret Access Key) Default region name [None]: us-east-1 Default output format [None]: json 测试配置是否生效 aws ec2 describe-vpcs 卸载（windows） # 控制面板 =&amp;gt; 程序和功能，找到aws cli，卸载即可。 安装kubectl cli # 如果你确实是使用EKS的Kubernetes，建议使用aws提供的kubectl命令工具。</description></item><item><title/><link>https://blog.poneding.com/aws/cluster-autoscaler/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/cluster-autoscaler/</guid><description>我的博客 / AWS / Cluster AutoScaler
Cluster AutoScaler # 我当前已经有了一个EKS服务搭建起来的K8s集群，我现在希望我的集群拥有自动伸缩（体现在节点的扩缩）的能力。
当我的集群资源充足，而我部署在集群中的应用只使用到了很少量的资源，我希望集群回收资源以节省费用；当我的应用服务越来越多，当前集群资源不足时，我希望集群能增加节点，以满足应用的部署条件。
那么本篇就是介绍如何通过使用Kubernetes Cluster Autoscaler让你的集群拥有自动伸缩的能力，而不用你时刻关注集群的资源是否过于宽松或紧张。
NodeGroup添加Tag # 我们创建EKS时，需要定义NodeGroup，一般在这个NodeGroup中定义:
asg_desired_capacity：期望创建的Node数量；
asg_max_size：最小Node数量，默认为1；
asg_min_size：最大Node数量。
定义的NodeGroup会生成Auto Scaling Group资源，并且由Auto Scaling Group来管理Node的创建。
现在需要做的就是为你的Auto Scaling Group添加Tag。
tag键值：
Tag Key Tag Value k8s.io/cluster-autoscaler/&amp;lt;your_cluster_name&amp;gt; owned k8s.io/cluster-autoscaler/enabled true 第一个Tag Key中的集群名&amp;lt;your_cluster_name&amp;gt;需要替换；
Tag Value的值是什么不重要，主要是需要这两个Tag Key来识别是否对这个集群开启Auto Scaling的能力。
添加Policy # 创建IAM策略，将新创建的策略Attach到集群节点绑定的IAM role上，让你的集群节点拥有自动伸缩的能力。
IAM策略Json内容：
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Action&amp;#34;: [ &amp;#34;autoscaling:DescribeAutoScalingGroups&amp;#34;, &amp;#34;autoscaling:DescribeAutoScalingInstances&amp;#34;, &amp;#34;autoscaling:DescribeLaunchConfigurations&amp;#34;, &amp;#34;autoscaling:DescribeTags&amp;#34;, &amp;#34;autoscaling:SetDesiredCapacity&amp;#34;, &amp;#34;autoscaling:TerminateInstanceInAutoScalingGroup&amp;#34;, &amp;#34;ec2:DescribeLaunchTemplateVersions&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34;, &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34; } ] } 部署Cluster AutoScaler # 在集群中部署Cluster AutoScaler，准备资源清单文件cluster-autoscaler.</description></item><item><title/><link>https://blog.poneding.com/aws/create-eks-cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/create-eks-cluster/</guid><description>我的博客 / AWS / 创建 EKS 集群
创建 EKS 集群 # 1. EKS简介 # Amazon Elastic Kubernetes Service (Amazon EKS) 是一项托管服务，可让您在 AWS 上轻松运行 Kubernetes，而无需支持或维护您自己的 Kubernetes 控制层面。Kubernetes 是一个用于实现容器化应用程序的部署、扩展和管理的自动化的开源系统。（该段介绍来自Amazon EKS文档，更多了解 https://docs.aws.amazon.com/zh_cn/eks/latest/userguide/what-is-eks.html）
2. eksctl创建eks集群 # 2.1 什么是eksctl # eksctl是一种用于在 Amazon EKS 上创建和管理 Kubernetes 集群的简单命令行实用程序。eksctl 命令行实用程序提供了使用工作线程节点为 Amazon EKS 创建新集群的最快、最简单的方式。
eksctl更多了解 https://eksctl.io
2.2 为什么用eksctl # 创建EKS集群可以在AWS的控制台创建，也可以使用AWS开发的eksctl工具创建，为什么选择使用eksctl创建eks集群呢，有以下几点原因：
直接在AWS的控制台创建集群，需要手动创建各种Role，以及选择合适的Subnet，Security Group等繁杂操作，你需要在浏览器中打开多个页面，操作过程可能也要时不时参阅文档； eksctl创建EKS集群只需要一行eksctl create cluster &amp;lt;参数&amp;gt;命令即可，会自动的给你创建Role等资源； eksctl的命令可以记录到脚本，便于复用。 2.3 安装eksctl（基于ubuntu） # 使用以下命令下载并提取最新版本的 eksctl。 curl --silent --location &amp;#34;https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz&amp;#34; | tar xz -C /tmp 将提取的二进制文件移至 /usr/local/bin。 sudo mv /tmp/eksctl /usr/local/bin 使用以下命令测试您的安装是否成功。 eksctl version 注意：</description></item><item><title/><link>https://blog.poneding.com/aws/eks-config-alb-ingress/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/eks-config-alb-ingress/</guid><description>我的博客 / AWS / EKS配置 ALB Ingress
EKS配置 ALB Ingress # 官方文档： https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/controller/installation/
部署Alb Ingress Controller # IAM中创建Policy，给集群的Node节点的Role添加该Policy。
Policy的JSON配置如下：
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;acm:DescribeCertificate&amp;#34;, &amp;#34;acm:ListCertificates&amp;#34;, &amp;#34;acm:GetCertificate&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;ec2:AuthorizeSecurityGroupIngress&amp;#34;, &amp;#34;ec2:CreateSecurityGroup&amp;#34;, &amp;#34;ec2:CreateTags&amp;#34;, &amp;#34;ec2:DeleteTags&amp;#34;, &amp;#34;ec2:DeleteSecurityGroup&amp;#34;, &amp;#34;ec2:DescribeAccountAttributes&amp;#34;, &amp;#34;ec2:DescribeAddresses&amp;#34;, &amp;#34;ec2:DescribeInstances&amp;#34;, &amp;#34;ec2:DescribeInstanceStatus&amp;#34;, &amp;#34;ec2:DescribeInternetGateways&amp;#34;, &amp;#34;ec2:DescribeNetworkInterfaces&amp;#34;, &amp;#34;ec2:DescribeSecurityGroups&amp;#34;, &amp;#34;ec2:DescribeSubnets&amp;#34;, &amp;#34;ec2:DescribeTags&amp;#34;, &amp;#34;ec2:DescribeVpcs&amp;#34;, &amp;#34;ec2:ModifyInstanceAttribute&amp;#34;, &amp;#34;ec2:ModifyNetworkInterfaceAttribute&amp;#34;, &amp;#34;ec2:RevokeSecurityGroupIngress&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;elasticloadbalancing:AddListenerCertificates&amp;#34;, &amp;#34;elasticloadbalancing:AddTags&amp;#34;, &amp;#34;elasticloadbalancing:CreateListener&amp;#34;, &amp;#34;elasticloadbalancing:CreateLoadBalancer&amp;#34;, &amp;#34;elasticloadbalancing:CreateRule&amp;#34;, &amp;#34;elasticloadbalancing:CreateTargetGroup&amp;#34;, &amp;#34;elasticloadbalancing:DeleteListener&amp;#34;, &amp;#34;elasticloadbalancing:DeleteLoadBalancer&amp;#34;, &amp;#34;elasticloadbalancing:DeleteRule&amp;#34;, &amp;#34;elasticloadbalancing:DeleteTargetGroup&amp;#34;, &amp;#34;elasticloadbalancing:DeregisterTargets&amp;#34;, &amp;#34;elasticloadbalancing:DescribeListenerCertificates&amp;#34;, &amp;#34;elasticloadbalancing:DescribeListeners&amp;#34;, &amp;#34;elasticloadbalancing:DescribeLoadBalancers&amp;#34;, &amp;#34;elasticloadbalancing:DescribeLoadBalancerAttributes&amp;#34;, &amp;#34;elasticloadbalancing:DescribeRules&amp;#34;, &amp;#34;elasticloadbalancing:DescribeSSLPolicies&amp;#34;, &amp;#34;elasticloadbalancing:DescribeTags&amp;#34;, &amp;#34;elasticloadbalancing:DescribeTargetGroups&amp;#34;, &amp;#34;elasticloadbalancing:DescribeTargetGroupAttributes&amp;#34;, &amp;#34;elasticloadbalancing:DescribeTargetHealth&amp;#34;, &amp;#34;elasticloadbalancing:ModifyListener&amp;#34;, &amp;#34;elasticloadbalancing:ModifyLoadBalancerAttributes&amp;#34;, &amp;#34;elasticloadbalancing:ModifyRule&amp;#34;, &amp;#34;elasticloadbalancing:ModifyTargetGroup&amp;#34;, &amp;#34;elasticloadbalancing:ModifyTargetGroupAttributes&amp;#34;, &amp;#34;elasticloadbalancing:RegisterTargets&amp;#34;, &amp;#34;elasticloadbalancing:RemoveListenerCertificates&amp;#34;, &amp;#34;elasticloadbalancing:RemoveTags&amp;#34;, &amp;#34;elasticloadbalancing:SetIpAddressType&amp;#34;, &amp;#34;elasticloadbalancing:SetSecurityGroups&amp;#34;, &amp;#34;elasticloadbalancing:SetSubnets&amp;#34;, &amp;#34;elasticloadbalancing:SetWebACL&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;iam:CreateServiceLinkedRole&amp;#34;, &amp;#34;iam:GetServerCertificate&amp;#34;, &amp;#34;iam:ListServerCertificates&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;cognito-idp:DescribeUserPoolClient&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;waf-regional:GetWebACLForResource&amp;#34;, &amp;#34;waf-regional:GetWebACL&amp;#34;, &amp;#34;waf-regional:AssociateWebACL&amp;#34;, &amp;#34;waf-regional:DisassociateWebACL&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;tag:GetResources&amp;#34;, &amp;#34;tag:TagResources&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;waf:GetWebACL&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; }, { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Action&amp;#34;: [ &amp;#34;shield:DescribeProtection&amp;#34;, &amp;#34;shield:GetSubscriptionState&amp;#34;, &amp;#34;shield:DeleteProtection&amp;#34;, &amp;#34;shield:CreateProtection&amp;#34;, &amp;#34;shield:DescribeSubscription&amp;#34;, &amp;#34;shield:ListProtections&amp;#34; ], &amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34; } ] } 下载alb-ingress-controller.</description></item><item><title/><link>https://blog.poneding.com/aws/eks-details/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/eks-details/</guid><description>我的博客 / AWS / EKS小细节汇总
EKS小细节汇总 # 如果alb的ingress使用了自定义的security group，那么需要将该安全组加入到worker
« EKS配置 ALB Ingress
» EKS实践 集成Gitlab自动发布（一）</description></item><item><title/><link>https://blog.poneding.com/aws/eks-intergrate-gitlab-auto-release-01/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/eks-intergrate-gitlab-auto-release-01/</guid><description>我的博客 / AWS / EKS实践 集成Gitlab自动发布（一）
EKS实践 集成Gitlab自动发布（一） # 系列介绍如何使用Gitlab CI/CD自动部署应用到EKS（K8s）集群中。本篇介绍如何在EKS（K8s）集群中为Gitlab的CI/CD创建Gitlab Runner。
Gitlab添加K8s集群 # 添加方式 # 第一种方式，基于单个仓库添加K8s集群：
进入Gitlab仓库，依次从左边菜单栏Operations =&amp;gt; Kubernetes进入添加页面，点击Add Kubernetes cluster按钮。这种方式添加的K8s集群只对该项目仓库有效。
第二种方式，基于Group添加K8s集群：
进入Gitlab主页，依次从上边菜单栏Groups =&amp;gt; Your groups，选择Group进入页面，然后依次从左边菜单栏Kuberentes进入添加页面，点击Add Kubernetes cluster。这种方式添加的K8s集群对该Group下的项目仓库有效。
第三种方式，基于全局添加K8s集群：
这种方式需要用到gitlab的root权限。进入Gitlab主页，从上边菜单栏Admin Area(扳手图标) 进入页面，然后依次从左边菜单栏Kuberentes进入添加页面，点击Add Kubernetes cluster。这种方式添加的K8s集群对所有项目仓库有效。
添加步骤 # 添加已有的K8s集群，按照如下步骤获取到对应的值填入表单即可。
Cluster Name： 这个可以自定义，能自行区分就行。
API URL： 运行以下命令得到输出值：
kubectl cluster-info | grep &amp;#39;Kubernetes master&amp;#39; | awk &amp;#39;/http/ {print $NF}&amp;#39; CA Certificate： 运行以下命令得到输出值：
kubectl get secret $(kubectl get secret | grep default-token | awk &amp;#39;{print $1}&amp;#39;) -o jsonpath=&amp;#34;{[&amp;#39;data&amp;#39;][&amp;#39;ca\.</description></item><item><title/><link>https://blog.poneding.com/aws/eks-intergrate-gitlab-auto-release-02/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/eks-intergrate-gitlab-auto-release-02/</guid><description>我的博客 / AWS / EKS实践 集成Gitlab自动发布（二）
EKS实践 集成Gitlab自动发布（二） # 系列介绍如何使用Gitlab CI/CD自动部署应用到EKS（K8s）集群中。本篇介绍如何为Runnr镜像的制作。
上文中创建的Gitlab Runner会持续存活在EKS集群中，但是它不做具体的Pipeline任务，当有Pipeline任务来临时，由它来创建临时的Runner来执行。而临时拆功创建的Runner使用什么容器环境以及具体执行什么任务是由仓库目录下.gitlab-ci.yml文件定义的。
制作Temp Runner镜像 # 我们制作这个镜像的目的是为了能让镜像运行起来后，可以完成我们的自动发布任务。比如在容器temp-runner容器需要将我们的代码build成应用镜像，然后将应用镜像发布到EKS集群，可以看到，在容器中我们就必须可以使用docker build功能以及kubectl apply功能。
按照以上的需要，我们制作的镜像至少需要安装好docker 以及kubectl。
Dockerfile如下：
FROM docker:18 RUN apk add --no-cache curl jq python3 git tar tree &amp;amp;&amp;amp; \ curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl &amp;amp;&amp;amp; chmod +x ./kubectl &amp;amp;&amp;amp; mv ./kubectl /usr/local/bin/kubectl 直接使用docker镜像作为基础镜像，然后安装kubectl
使用命令制作并推送镜像到dockerhub（实际我的镜像推动到了ECR）
docker build . -t gitlab-runner-base:latest --rm --no-cache docker push gitlab-runner-base:latest 仓库配置 # 项目仓库根目录下新增.gitlab-ci.yml文件，然后文件内容
« EKS实践 集成Gitlab自动发布（一）
» EKS-使用EFS</description></item><item><title/><link>https://blog.poneding.com/aws/eks-use-efs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/eks-use-efs/</guid><description>我的博客 / AWS / EKS-使用EFS
EKS-使用EFS # 创建EFS
aws efs create-file-system \ --performance-mode generalPurpose \ --throughput-mode bursting \ --encrypted \ --tags Key=Name,Value=&amp;lt;fs-name&amp;gt; Key=creator,Value=dp Key=env:dev,Value=1 # 上面的命令会得到fs-id aws efs create-mount-target \ --file-system-id &amp;lt;fs-id&amp;gt; \ --subnet-id subnet-08d7609e614373fb8 \ --security-groups sg-0af0f0e8705380529 aws efs create-mount-target \ --file-system-id &amp;lt;fs-id&amp;gt; \ --subnet-id subnet-09c0707ea8ad281bb \ --security-groups sg-0af0f0e8705380529 aws efs create-mount-target \ --file-system-id &amp;lt;fs-id&amp;gt; \ --subnet-id subnet-063a8f10feb97868d \ --security-groups sg-0af0f0e8705380529 « EKS实践 集成Gitlab自动发布（二）
» Gitlab &amp;amp; EKS</description></item><item><title/><link>https://blog.poneding.com/aws/gitlab-eks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/gitlab-eks/</guid><description>我的博客 / AWS / Gitlab &amp;amp; EKS
Gitlab &amp;amp; EKS # 创建IAM User&amp;amp;Group # User：gitlab-ci，保存生成的Access key ID和Secret Access Key，后面会用到
Group：Gitlab.CI，添加Policy如下：
Policy Name AmazonEKSWorkerNodePolicy AmazonEC2ContainerRegistryFullAccess AmazonEC2ContainerRegistryReadOnly AmazonEC2ContainerServiceFullAccess AmazonEKS_CNI_Policy 将user gitlab-ci添加到Group Gitlab.CI
将IAM User添加到ConfigMap # kubectl edit cm aws-auth -n kube-system 在mapUsers键追加：
- &amp;#34;groups&amp;#34;: - &amp;#34;system:masters&amp;#34; &amp;#34;userarn&amp;#34;: &amp;#34;arn:aws:iam::xxxxxxx:user/gitlab-ci&amp;#34; &amp;#34;username&amp;#34;: &amp;#34;gitlab-ci&amp;#34; Gitlab仓库设置 # Setting =&amp;gt; CI/CD =&amp;gt; Variables，添加变量：
AWS_ACCESS_KEY_ID：&amp;lt;gitlab-ci用户的Access key ID&amp;gt; AWS_SECRET_ACCESS_KEY：&amp;lt;gitlab-ci用户的Secret Access Key&amp;gt; Gitlab仓库.gitlab-ci.yml # « EKS-使用EFS
» K8s 部署 Kong 服务</description></item><item><title/><link>https://blog.poneding.com/aws/k8s-deploy-kong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/k8s-deploy-kong/</guid><description>我的博客 / AWS / K8s 部署 Kong 服务
K8s 部署 Kong 服务 # 本篇只涉及 Kong 服务在 K8s 集群的部署操作，不涉及概念知识。
提前准备 # K8s 集群，本文使用的是 AWS EKS 集群服务 一台可以连接 K8s 集群的服务器，已经安装 kubectl 和 docker 等基础应用，之后称之为操作机器 Postgres 数据库，作为 Kong 服务的后端数据库 初始化数据库 # 使用 Postgres 作为 Kong 服务的后端数据库，我们需要提前做数据库的初始化，准备 Kong 服务需要的数据表等。这里使用 K8s-Job 来实现数据库的初始化工作。
kong-migrations-job.yaml：
apiVersion: batch/v1 kind: Job metadata: name: kong-migrations namespace: kong spec: template: metadata: name: kong-migrations spec: containers: - command: - /bin/sh - -c - kong migrations bootstrap env: - name: KONG_PG_PASSWORD value: &amp;#34;kong&amp;#34; - name: KONG_PG_HOST value: &amp;#34;postgres/postgres&amp;#34; - name: KONG_PG_PORT value: &amp;#34;5432&amp;#34; image: kong:1.</description></item><item><title/><link>https://blog.poneding.com/aws/k8s-deploy-konga/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/k8s-deploy-konga/</guid><description>我的博客 / AWS / K8s 部署 konga
K8s 部署 konga # 本篇只涉及 konga 的部署操作，不涉及概念知识。
提前准备 # K8s 集群，本文使用的是 AWS EKS 集群服务 一台可以连接 K8s 集群的服务器，已经安装 kubectl 和 docker 等基础应用，之后称之为操作机器 Postgres数据库 ！注意：该数据库使用 9.5 版本，其他最新版本的数据库在初始化 konga 数据库时会报如下错：
error: Failed to prepare database: error: column r.consrc does not exist 这是部署 konga 踩过的坑之一。
确保 K8s 集群中已经创建了 nginx-ingress，nginx-ingress 用于根据定制的 Rule（如后文 kong-ingress 的配置）将流量转发至 K8s 集群的 Service 中去。 创建 nginx-ingress 指令（可参照 https://kubernetes.github.io/ingress-nginx/deploy/）步骤如下：
Step 1. 执行以下强制命令
kubectl apply -f https://raw.</description></item><item><title/><link>https://blog.poneding.com/aws/k8s-deploy-postgres/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/k8s-deploy-postgres/</guid><description>我的博客 / AWS / K8s 部署 Postgres
K8s 部署 Postgres # 本篇只涉及 Postgres 的部署操作，不涉及概念知识。
特别说明：Postgres 相对于普通的程序应用而言，属于有状态的服务，因为它存储的数据是需要持久保存的，这点决定了我们选择 K8s-StatefulSet 的部署而非 K8s-Deployment。
提前准备 # K8s 集群，本文使用的是AWS EKS集群服务 一台可以连接 K8s 集群的服务器，已经安装 kubectl 和 docker 等基础应用 K8s资源文件 # postgres-namespace.yaml：
apiVersion: v1 kind: Namespace metadata: name: postgres postgres-config.yaml：
apiVersion: v1 kind: ConfigMap metadata: name: postgres-config namespace: postgres labels: app: postgres data: POSTGRES_DB: master POSTGRES_USER: dba POSTGRES_PASSWORD: pg_pass 这里的数据库密码涉及到信息敏感，更建议使用 Secret 资源而非 ConfigMap，这里就偷懒了。
postgres-statefulset.yaml：
apiVersion: apps/v1 kind: StatefulSet metadata: name: postgres namespace: postgres spec: serviceName: &amp;#34;postgres&amp;#34; replicas: 1 selector: matchLabels: app: postgres template: metadata: labels: app: postgres spec: containers: - name: postgres image: postgres:9.</description></item><item><title/><link>https://blog.poneding.com/aws/terraform-remanage-resource/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://blog.poneding.com/aws/terraform-remanage-resource/</guid><description>我的博客 / AWS / Terraform 重新管理资源
Terraform 重新管理资源 # 看到这个标题你可能会有点懵，我先来解释下。
在使用Terraform管理AWS的VPC-Subnet资源时（下面是定义资源的代码清单），我遇到了一个问题：当我修改aws_subnet.eks-private-subnet-1资源的cidr_block时，假设我修改成了172.28.2.0/24，这时候旧的
resource &amp;#34;aws_subnet&amp;#34; &amp;#34;eks-private-subnet-1&amp;#34; { vpc_id = &amp;#34;${var.vpc_id}&amp;#34; cidr_block = &amp;#34;172.28.1.0/24&amp;#34; map_public_ip_on_launch = &amp;#34;false&amp;#34; availability_zone = &amp;#34;${var.region}a&amp;#34; tags = merge( {Name = &amp;#34;${var.cluster_name}-private-subnet-1a&amp;#34;}, &amp;#34;${local.cluster_private_subnet_tags}&amp;#34;) } « K8s 部署 Postgres</description></item></channel></rss>