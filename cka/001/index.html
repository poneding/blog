<!doctype html><html lang=cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="ğŸ  é¦–é¡µ / CKA / 001
001 # 01 Task - è‹±æ–‡ # Create a new ClusterRole named deployment-clusterrole that only allows the creation of the following resource types:
Deployment StatefulSet DaemonSet Create a new ServiceAccount named cicd-token in the existing namespace app-team1. Limited to namespace app-team1, bind the new ClusterRole deployment-clusterrole to the new ServiceAccount cicd-token. kubectl create ns app-team1 kubectl create serviceaccount cicd-token -n app-team1 kubectl create clusterrole deployment-clusterrole --verb=create --resource=deployment,statefulset,daemonset #limted to the namespace app-team1ã€‚éœ€è¦é™åˆ¶çš„æ˜¯namespaceçº§åˆ«ï¼Œclusterrolebindingä¸ºè®¾ç½®å…¨å±€ï¼Œrolebindingæ­£ç¡® kubectl create rolebinding cicd-clusterrole -n app-team1 --clusterrole=deployment-clusterrole --serviceaccount=app-team1:cicd-token 02 Task - è‹±æ–‡ # Set the node named ek8s-node-1 as unavaliable and reschedule all the pods running on it."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://blog.poneding.com/cka/001/"><meta property="og:site_name" content="ç§‹æ²³è½å¶"><meta property="og:title" content="ç§‹æ²³è½å¶"><meta property="og:description" content="ğŸ  é¦–é¡µ / CKA / 001
001 # 01 Task - è‹±æ–‡ # Create a new ClusterRole named deployment-clusterrole that only allows the creation of the following resource types:
Deployment StatefulSet DaemonSet Create a new ServiceAccount named cicd-token in the existing namespace app-team1. Limited to namespace app-team1, bind the new ClusterRole deployment-clusterrole to the new ServiceAccount cicd-token. kubectl create ns app-team1 kubectl create serviceaccount cicd-token -n app-team1 kubectl create clusterrole deployment-clusterrole --verb=create --resource=deployment,statefulset,daemonset #limted to the namespace app-team1ã€‚éœ€è¦é™åˆ¶çš„æ˜¯namespaceçº§åˆ«ï¼Œclusterrolebindingä¸ºè®¾ç½®å…¨å±€ï¼Œrolebindingæ­£ç¡® kubectl create rolebinding cicd-clusterrole -n app-team1 --clusterrole=deployment-clusterrole --serviceaccount=app-team1:cicd-token 02 Task - è‹±æ–‡ # Set the node named ek8s-node-1 as unavaliable and reschedule all the pods running on it."><meta property="og:locale" content="cn"><meta property="og:type" content="article"><meta property="article:section" content="cka"><meta property="article:modified_time" content="2024-06-13T15:37:18+08:00"><title>1st | ç§‹æ²³è½å¶</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/logo.png><link rel=canonical href=https://blog.poneding.com/cka/001/><link rel=stylesheet href=/book.min.4964903a822a7acb10dac6d1ab524833c97fb5f99b141976bcb8a47d539be9c0.css integrity="sha256-SWSQOoIqessQ2sbRq1JIM8l/tfmbFBl2vLikfVOb6cA=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/cn.search.min.7e8e632082b64179ac04f2ccb8c70e4ca452306203f0dfe3e3444e034ededbf2.js integrity="sha256-fo5jIIK2QXmsBPLMuMcOTKRSMGID8N/j40ROA07e2/I=" crossorigin=anonymous></script><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script><link rel=stylesheet href=/css/syntax.css></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo><span>ç§‹æ²³è½å¶</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=æœç´¢ aria-label=æœç´¢ maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><p>ğŸ¦‰ é›†ä¸­èµ·æ¥çš„æ„å¿—å¯ä»¥å‡»ç©¿é¡½çŸ³ã€‚</p><hr><ul><li><p><a href=/><strong>ğŸ  é¦–é¡µ</strong></a></p></li><li><p><strong>ğŸ“Œ ç½®é¡¶æ–‡ç« </strong></p><ul><li><a href=/git/common-usage/>Git å¸¸ç”¨</a></li><li><a href=/kubernetes/kubeadm-install-k8s-docker/>å®‰è£… Kubernetes (Docker)</a></li></ul></li><li><p><strong>ğŸ“Œ ç½®é¡¶åˆ†ç±»</strong></p><ul><li><a href=/go/>Golang ç¼–ç¨‹</a></li><li><a href=/kubernetes/>Kubernetes</a></li><li><a href=/rust/>Rust ç¼–ç¨‹</a></li><li><a href=/git/>Git</a></li></ul></li></ul><hr><ul><li><strong>ğŸ—ƒï¸ å¼€æºé¡¹ç›®</strong><ul><li><a href=https://github.com/ketches/registry-proxy>registry-proxy</a></li><li><a href=https://github.com/poneding/mdi>mdi</a></li></ul></li></ul><hr><ul><li><a href=https://github.com/poneding target=_blank rel=noopener>ğŸ™ GitHub</a></li><li><a href=mailto:poneding@gmail.com target=_blank rel=noopener>ğŸ“¬ é‚®ç®±</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>1st</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#01-task---è‹±æ–‡>01 Task - è‹±æ–‡</a></li><li><a href=#02-task---è‹±æ–‡>02 Task - è‹±æ–‡</a></li><li><a href=#03-task---è‹±æ–‡>03 Task - è‹±æ–‡</a></li><li><a href=#04-task---ä¸­æ–‡>04 Task - ä¸­æ–‡</a></li><li><a href=#05-task---è‹±æ–‡>05 Task - è‹±æ–‡</a></li><li><a href=#06-task---è‹±æ–‡>06 Task - è‹±æ–‡</a></li><li><a href=#07-task---è‹±æ–‡>07 Task - è‹±æ–‡</a></li><li><a href=#08-task---è‹±æ–‡>08 Task - è‹±æ–‡</a></li><li><a href=#09-task---è‹±æ–‡>09 Task - è‹±æ–‡</a></li><li><a href=#10-task---è‹±æ–‡>10 Task - è‹±æ–‡</a></li><li><a href=#11-task---è‹±æ–‡>11 Task - è‹±æ–‡</a></li><li><a href=#12-task---è‹±æ–‡>12 Task - è‹±æ–‡</a></li><li><a href=#13-task---è‹±æ–‡>13 Task - è‹±æ–‡</a></li><li><a href=#14-task---è‹±æ–‡>14 Task - è‹±æ–‡</a></li><li><a href=#15-task---è‹±æ–‡>15 Task - è‹±æ–‡</a></li><li><a href=#16-task---è‹±æ–‡>16 Task - è‹±æ–‡</a></li><li><a href=#17-task---è‹±æ–‡>17 Task - è‹±æ–‡</a></li><li><a href=#19-task---è‹±æ–‡>19 Task - è‹±æ–‡</a></li><li><a href=#é™æ€podåˆ›å»ºæ–¹æ³•ä¸æ³¨æ„ç‚¹>é™æ€Podåˆ›å»ºæ–¹æ³•ä¸æ³¨æ„ç‚¹</a></li></ul></nav></aside></header><article class="markdown book-article"><p><a href=/>ğŸ  é¦–é¡µ</a> /
<a href=/cka/>CKA</a> / 001</p><h1 id=001>001
<a class=anchor href=#001>#</a></h1><h2 id=01-task---è‹±æ–‡>01 Task - è‹±æ–‡
<a class=anchor href=#01-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Create a new ClusterRole named deployment-clusterrole that only allows the creation of the following resource types:</p><ul><li>Deployment</li><li>StatefulSet</li><li>DaemonSet
Create a new ServiceAccount named cicd-token in the existing namespace app-team1.
Limited to namespace app-team1, bind the new ClusterRole deployment-clusterrole to the new ServiceAccount cicd-token.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl create ns app-team1
</span></span><span class=line><span class=cl>kubectl create serviceaccount cicd-token -n app-team1
</span></span><span class=line><span class=cl>kubectl create clusterrole deployment-clusterrole --verb<span class=o>=</span>create --resource<span class=o>=</span>deployment,statefulset,daemonset
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#limted to the namespace app-team1ã€‚éœ€è¦é™åˆ¶çš„æ˜¯namespaceçº§åˆ«ï¼Œclusterrolebindingä¸ºè®¾ç½®å…¨å±€ï¼Œrolebindingæ­£ç¡®</span>
</span></span><span class=line><span class=cl>kubectl create rolebinding cicd-clusterrole -n app-team1 --clusterrole<span class=o>=</span>deployment-clusterrole --serviceaccount<span class=o>=</span>app-team1:cicd-token
</span></span></code></pre></div><h2 id=02-task---è‹±æ–‡>02 Task - è‹±æ–‡
<a class=anchor href=#02-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Set the node named ek8s-node-1 as unavaliable and reschedule all the pods running on it.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl cordon ek8s-node-1
</span></span><span class=line><span class=cl>kubectl drain ek8s-node-1 --delete-local-data --ignore-daemonsets --force
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>//åˆ é™¤æ‰€æœ‰podï¼ˆåŒ…æ‹¬daemonsetç®¡ç†çš„podï¼‰ï¼Œåˆ™éœ€è¦--ignore-daemonsetsæˆ–--ignore-daemonsets<span class=o>=</span><span class=nb>true</span>
</span></span></code></pre></div><h2 id=03-task---è‹±æ–‡>03 Task - è‹±æ–‡
<a class=anchor href=#03-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Given an existing Kubernetes cluster running version 1.18.8ï¼Œupgrade all of Kubernetes control plane and node components <strong>on the master node only</strong> to version 1.19.0ã€‚</p><p>You are also expected to upgrade kubelet and kubectl on the master nodeã€‚</p><blockquote><p>Be sure to drain the master node
before upgrading it and uncordon it after the upgrade.
Do not upgrade the worker nodes,etcd,the container manager,the CNI plugin,the DNS service or any other addons.</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>apt update
</span></span><span class=line><span class=cl>apt-cache policy kubeadm
</span></span><span class=line><span class=cl>apt-get update <span class=o>&amp;&amp;</span> apt-get install -y --allow-change-held-packages <span class=nv>kubeadm</span><span class=o>=</span>1.19.0
</span></span><span class=line><span class=cl>kubeadm version <span class=c1>#æ£€æŸ¥kubeadmç‰ˆæœ¬</span>
</span></span><span class=line><span class=cl>kubectl drain master --ignore-daemonsets --delete-local-data --force <span class=c1>#è…¾ç©ºæ§åˆ¶å¹³é¢èŠ‚ç‚¹</span>
</span></span><span class=line><span class=cl>sudo kubeadm upgrade plan <span class=c1># å‘½ä»¤æŸ¥çœ‹å¯å‡çº§çš„ç‰ˆæœ¬ä¿¡æ¯</span>
</span></span><span class=line><span class=cl>sudo kubeadm upgrade apply v1.19.0 --etcd-upgrade<span class=o>=</span><span class=nb>false</span> <span class=c1>#æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯æ—¶ï¼Œæ’é™¤etcdä»3.4.3-0å‡åˆ°3.4.7-0</span>
</span></span><span class=line><span class=cl>kubectl uncordon master
</span></span><span class=line><span class=cl>sudo kubeadm upgrade node <span class=c1>#å‡çº§å…¶ä»–æ§åˆ¶é¢èŠ‚ç‚¹</span>
</span></span><span class=line><span class=cl>apt-get update <span class=o>&amp;&amp;</span> apt-get install -y --allow-change-held-packages <span class=nv>kubelet</span><span class=o>=</span>1.19.0 <span class=nv>kubectl</span><span class=o>=</span>1.19.0
</span></span><span class=line><span class=cl><span class=c1>#å‡çº§å…¶ä»–æ§åˆ¶é¢èŠ‚ç‚¹</span>
</span></span><span class=line><span class=cl>sudo systemctl daemon-reload
</span></span><span class=line><span class=cl>sudo systemctl restart kubelet
</span></span></code></pre></div><h2 id=04-task---ä¸­æ–‡>04 Task - ä¸­æ–‡
<a class=anchor href=#04-task---%e4%b8%ad%e6%96%87>#</a></h2><p>é¦–å…ˆï¼Œä¸ºè¿è¡Œåœ¨
<a href=https://127.0.0.1:2379>https://127.0.0.1:2379</a> ä¸Šçš„ç°æœ‰etcd å®ä¾‹åˆ›å»ºå¿«ç…§å¹¶å°†å¿«ç…§ä¿å­˜åˆ°/data/backup/etcd-snapshot.dbã€‚</p><blockquote><p>ä¸ºç»™å®šå®ä¾‹åˆ›å»ºå¿«ç…§é¢„è®¡èƒ½åœ¨å‡ ç§’é’Ÿå†…å®Œæˆã€‚å¦‚æœè¯¥æ“ä½œä¼¼ä¹æŒ‚èµ·ï¼Œåˆ™å‘½ä»¤å¯èƒ½æœ‰é—®é¢˜ã€‚ç”¨ctrl+c æ¥å–æ¶ˆæ“ä½œï¼Œç„¶åé‡è¯•ã€‚</p></blockquote><p>ç„¶åè¿˜åŸä½äº/var/data/etcd-snapshot-previous.dbçš„ç°æœ‰å…ˆå‰å¿«ç…§ã€‚</p><blockquote><p>æä¾›äº†ä»¥ä¸‹TLSè¯ä¹¦å’Œå¯†é’¥ï¼Œä»¥é€šè¿‡etcdctlè¿æ¥åˆ°æœåŠ¡å™¨ã€‚</p><ul><li>caè¯ä¹¦ï¼š/opt/KUIN00601/ca.crt</li><li>å®¢æˆ·ç«¯è¯ä¹¦ï¼š/opt/KUIN00601/etcd-client.crt</li><li>å®¢æˆ·ç«¯å¯†é’¥ï¼š/opt/KUIN00601/etcd-client.key</li></ul></blockquote><p>ä¸€å®šè¦æŠŠè¿™å‚æ•°ç”¨ç†Ÿç»ƒï¼Œå¦‚æœè€ƒè¯•æ—¶æœ‰é—®é¢˜ï¼Œä¸è¦æ€¥ï¼Œå¤šè¯•è¯•ï¼ï¼ï¼</p><blockquote><p>ä¸€æ—¦æ­£ç¡®é…ç½®äº† etcdï¼Œåªæœ‰å…·æœ‰æœ‰æ•ˆè¯ä¹¦çš„å®¢æˆ·ç«¯æ‰èƒ½è®¿é—®å®ƒã€‚è¦è®© Kubernetes API æœåŠ¡å™¨è®¿é—®ï¼Œå¯ä»¥ä½¿ç”¨å‚æ•° &ndash;etcd-certfile=k8sclient.cert,â€“etcd-keyfile=k8sclient.key å’Œ &ndash;etcd-cafile=ca.cert é…ç½®å®ƒã€‚</p></blockquote><p>æˆ‘è®°å¾—æˆ‘è€ƒè¯•è¿›ç”¨çš„æ˜¯ï¼šâ€“certfile=/opt/KUIN00601/etcd-client.crt &ndash;keyfile=/opt/KUIN00601/etcd-client.key &ndash;cafile=/opt/KUIN00601/ca.crt</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>ETCDCTL_API</span><span class=o>=</span><span class=m>3</span> etcdctl --endpoint<span class=o>=</span>https://127.0.0.1:2379 --certfile<span class=o>=</span>/opt/KUIN00601/etcd-client.crt --keyfile<span class=o>=</span>/opt/KUIN00601/etcd-client.key --cafile<span class=o>=</span>/opt/KUIN00601/ca.crt snapshot save /data/backup/etcd-snapshot.db
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>ETCDCTL_API</span><span class=o>=</span><span class=m>3</span> etcdctl --endpoint<span class=o>=</span>https://127.0.0.1:2379 --cert-file<span class=o>=</span>/opt/KUIN00601/etcd-client.crt --key-file<span class=o>=</span>/opt/KUIN00601/etcd-client.key --ca-file<span class=o>=</span>/opt/KUIN00601/ca.crt snapshot restore /var/data/etcd-snapshot-previous.db
</span></span></code></pre></div><h2 id=05-task---è‹±æ–‡>05 Task - è‹±æ–‡
<a class=anchor href=#05-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Create a new <strong>NetworkPolicy</strong> named <strong>allow-port-from-namespace</strong> to allow Pods in the existing namespace <strong>internal</strong> to connect to port <strong>8080</strong> of other Pods in the same namespace.
Ensure that the new NetworkPolicy:</p><ul><li>does <strong>not</strong> allow access to Pods not listening on port <strong>8080</strong>.</li><li>does <strong>not</strong> allow access from Pods not in namespace <strong>internal</strong>.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>#network.yaml</span>
</span></span><span class=line><span class=cl>apiVersion: networking.k8s.io/v1
</span></span><span class=line><span class=cl>kind: NetworkPolicy
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: allow-port-from-namespace
</span></span><span class=line><span class=cl>  namespace: internal
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  podSelector: 
</span></span><span class=line><span class=cl>    matchLabels: <span class=o>{}</span>
</span></span><span class=line><span class=cl>  policyTypes:
</span></span><span class=line><span class=cl>  - Ingress
</span></span><span class=line><span class=cl>  ingress:
</span></span><span class=line><span class=cl>  - from: 
</span></span><span class=line><span class=cl>    - podSelector: <span class=o>{}</span> 
</span></span><span class=line><span class=cl>  ports: 
</span></span><span class=line><span class=cl>  - protocol: TCP 
</span></span><span class=line><span class=cl>    port: <span class=m>8080</span>
</span></span><span class=line><span class=cl><span class=c1>#spec.podSelectoré™å®šäº†è¿™ä¸ªnamespaceé‡Œçš„podå¯ä»¥è®¿é—®</span>
</span></span><span class=line><span class=cl>kubectl create -f network.yaml
</span></span></code></pre></div><h2 id=06-task---è‹±æ–‡>06 Task - è‹±æ–‡
<a class=anchor href=#06-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Reconfigure the existing deployment <strong>front-end</strong> and add a port specifiction named <strong>http</strong> exposing port <strong>80/tcp</strong> of the existing container <strong>nginx</strong>.</p><p>Create a new service named <strong>front-end-svc</strong> exposing the container prot <strong>http</strong>.</p><p>Configure the new service to also expose the individual Pods via a NodePort on the nodes on which they are scheduled.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get deploy front-end
</span></span><span class=line><span class=cl>kubectl edit deploy front-end -o yaml
</span></span><span class=line><span class=cl><span class=c1>#port specification named http</span>
</span></span><span class=line><span class=cl><span class=c1>#service.yaml</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Service
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: front-end-svc
</span></span><span class=line><span class=cl>  labels: app: nginx
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  ports:
</span></span><span class=line><span class=cl>  - port: <span class=m>80</span> protocol: tcp name: http
</span></span><span class=line><span class=cl>  selector: app: nginx
</span></span><span class=line><span class=cl>  type: NodePort  
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl>kubectl create -f service.yaml
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl>kubectl get svc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#æˆ–è€…ä¸€æ¡å‘½ä»¤æå®š,æ³¨æ„ä¼šé—æ¼port specification named http</span>
</span></span><span class=line><span class=cl>kubectl expose deployment front-end --name<span class=o>=</span>front-end-svc --port<span class=o>=</span><span class=m>80</span> --tarport<span class=o>=</span><span class=m>80</span> --type<span class=o>=</span>NodePort
</span></span></code></pre></div><h2 id=07-task---è‹±æ–‡>07 Task - è‹±æ–‡
<a class=anchor href=#07-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Create a new nginx Ingress resource as follows:</p><ul><li>Name: <strong>ping</strong>ï¼š</li><li>Namespace: <strong>ing-internal</strong>ï¼š</li><li>Exposing service <strong>hi</strong> on path <strong>/hi</strong> using service port <strong>5678</strong>ï¼š</li></ul><blockquote><p>The avaliability of service <strong>hi</strong> can be checked using the following command,which should return <strong>hi</strong>:
curl -kL /hi</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vi ingress.yaml
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl>apiVersion: networking.k8s.io/v1
</span></span><span class=line><span class=cl>kind: Ingress
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: ping
</span></span><span class=line><span class=cl>  namespace: ing-internal
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  rules:
</span></span><span class=line><span class=cl>  - http: paths: - path: /hi pathType: Prefix backend: service: name: hi port: number: <span class=m>5678</span>
</span></span><span class=line><span class=cl><span class=c1># </span>
</span></span><span class=line><span class=cl>kubectl create -f ingress.yaml
</span></span></code></pre></div><h2 id=08-task---è‹±æ–‡>08 Task - è‹±æ–‡
<a class=anchor href=#08-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Scale the deployment <strong>presentation</strong> to <strong>3</strong> pods.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl get deployment
</span></span><span class=line><span class=cl>kubectl scale deployment.apps/presentation --replicas<span class=o>=</span><span class=m>3</span>
</span></span></code></pre></div><h2 id=09-task---è‹±æ–‡>09 Task - è‹±æ–‡
<a class=anchor href=#09-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Task</p><p>Schedule a pod as follows:</p><ul><li>name: <strong>nginx-kusc00401</strong>ï¼š</li><li>Image: <strong>nginx</strong>ï¼š</li><li>Node selector: <strong>disk-spinning</strong>ï¼š</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>#yaml</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Pod
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: nginx-kusc00401
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  containers:
</span></span><span class=line><span class=cl>  - name: nginx image: nginx imagePullPolicy: IfNotPresent
</span></span><span class=line><span class=cl>  nodeSelector: disk: spinning
</span></span><span class=line><span class=cl><span class=c1># </span>
</span></span><span class=line><span class=cl>kubectl create -f node-select.yaml 
</span></span></code></pre></div><h2 id=10-task---è‹±æ–‡>10 Task - è‹±æ–‡
<a class=anchor href=#10-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Task
Check to see how many nodes are ready (not including nodes tainted <strong>NoSchedule</strong>)and write the number to <strong>/opt/KUSC00402/kusc00402.txt.</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl describe nodes <span class=p>|</span> grep ready<span class=p>|</span>wc -l
</span></span><span class=line><span class=cl>kubectl describe nodes <span class=p>|</span> grep -i taint <span class=p>|</span> grep -i noschedule <span class=p>|</span>wc -l
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=m>3</span> &gt; /opt/KUSC00402/kusc00402.txt
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># æŸ¥è¯¢é›†ç¾¤ReadyèŠ‚ç‚¹æ•°é‡</span>
</span></span><span class=line><span class=cl>kubectl get node <span class=p>|</span> grep -i ready <span class=p>|</span>wc -l
</span></span><span class=line><span class=cl><span class=c1># æ‰¾å‡ºèŠ‚ç‚¹taintsã€noSchedule</span>
</span></span><span class=line><span class=cl>kubectl describe nodes <span class=p>|</span> grep -i taints <span class=p>|</span> grep -i noschedule <span class=p>|</span>wc -l
</span></span><span class=line><span class=cl><span class=c1>#å°†å¾—åˆ°çš„å‡æ•°ï¼Œå†™å…¥åˆ°æ–‡ä»¶</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=m>2</span> &gt; /opt/KUSC00402/kusc00402.txt
</span></span></code></pre></div><h2 id=11-task---è‹±æ–‡>11 Task - è‹±æ–‡
<a class=anchor href=#11-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Create a pod named <strong>kucc8</strong> with a single app container for each of the following images running inside (there may be between 1 and 4 images specified):
<strong>nginx + redis + memcached + consul .</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl run kucc8 --image<span class=o>=</span>nginx --dry-run -o yaml &gt; kucc8.yaml
</span></span><span class=line><span class=cl><span class=c1># vi kucc8.yaml</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Pod
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  creationTimestamp: null
</span></span><span class=line><span class=cl>  name: kucc8
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  containers:
</span></span><span class=line><span class=cl>  - image: nginx name: nginx
</span></span><span class=line><span class=cl>  - image: redis name: redis
</span></span><span class=line><span class=cl>  - image: memcached name: memcached
</span></span><span class=line><span class=cl>  - image: consul name: consul
</span></span><span class=line><span class=cl><span class=c1># </span>
</span></span><span class=line><span class=cl>kubectl create -f kucc8.yaml
</span></span><span class=line><span class=cl><span class=c1>#12.07</span>
</span></span></code></pre></div><h2 id=12-task---è‹±æ–‡>12 Task - è‹±æ–‡
<a class=anchor href=#12-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Task
Create a persistent volume whit name <strong>app-config</strong>, of capacity <strong>1Gi</strong> and access mode ReadOnlyMany . the type of volume is <strong>hostPath</strong> and its location is <strong>/srv/app-config .</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>#vi pv.yaml</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: PersistentVolume
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: app-config
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  capacity: storage: 1Gi
</span></span><span class=line><span class=cl>  accessModes: - ReadOnlyMany
</span></span><span class=line><span class=cl>  hostPath: path: /srv/app-config
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl>kubectl create -f pv.yaml
</span></span></code></pre></div><h2 id=13-task---è‹±æ–‡>13 Task - è‹±æ–‡
<a class=anchor href=#13-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Task
Create a new <strong>PersistentVolumeClaim</strong>:</p><ul><li>Name: <strong>pv-volume</strong>ï¼š</li><li>Class: <strong>csi-hostpath-sc</strong>ï¼š</li><li>Capacity: <strong>10Mi</strong>ï¼š</li></ul><p>Create a new Pod which mounts the <strong>PersistentVolumeClaim</strong> as a volume:</p><ul><li>Name: <strong>web-server</strong>ï¼š</li><li>Image: <strong>nginx</strong>ï¼š</li><li>Mount path: <strong>/usr/share/nginx/html</strong>ï¼š</li></ul><p>Configure the new Pod to have <strong>ReadWriteOnce</strong> access on the volume.</p><p>Finally,using <strong>kubectl edit</strong> or <strong>Kubectl patch</strong> expand the <strong>PersistentVolumeClaim</strong> to a capacity of <strong>70Mi</strong> and record that change.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vi pvc.yaml
</span></span><span class=line><span class=cl><span class=c1>#ä½¿ç”¨æŒ‡å®šstorageclassåˆ›å»ºä¸€ä¸ªpvc</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: PersistentVolumeClaim
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: pv-volume
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  accessModes: - ReadWriteOnce
</span></span><span class=line><span class=cl>  volumeMode: Filesystem resources: requests: storage: 10Mi
</span></span><span class=line><span class=cl>  storageClassName: csi-hostpath-sc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># vi pod-pvc.yaml</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Pod
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: web-server
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  containers: - name: web-server image: nginx volumeMounts: - mountPath: <span class=s2>&#34;/usr/share/nginx/html&#34;</span> name: my-volume
</span></span><span class=line><span class=cl>  volumes: - name: my-volume persistentVolumeClaim: claimName: pv-volume
</span></span><span class=line><span class=cl><span class=c1># craete </span>
</span></span><span class=line><span class=cl>kubectl create -f pod-pvc.yaml
</span></span><span class=line><span class=cl><span class=c1>#edit ä¿®æ”¹å®¹é‡</span>
</span></span><span class=line><span class=cl>kubectl edit pvc pv-volume --record
</span></span></code></pre></div><h2 id=14-task---è‹±æ–‡>14 Task - è‹±æ–‡
<a class=anchor href=#14-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Task
Monitor the logs of pod <strong>bar</strong> and:</p><ul><li>Extract log lines corresponding to error <strong>unable-to-access-website</strong>ï¼š</li><li>Write them to <strong>/opt/KUTR00101/bar</strong>ï¼š</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl logs bar <span class=p>|</span> grep <span class=s1>&#39;unable-to-access-website&#39;</span> &gt; /opt/KUTR00101/bar
</span></span><span class=line><span class=cl>cat /opt/KUTR00101/bar
</span></span></code></pre></div><h2 id=15-task---è‹±æ–‡>15 Task - è‹±æ–‡
<a class=anchor href=#15-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Context
Without changing its existing containers,an existing Pod needs to be integrated into Kubernetesâ€™s build-in logging architecture (e.g. kubectl logs). Adding a streaming sidecar container is a good and common way to accomplish this requirement.</p><p>Task
Add a <strong>busybox</strong> sidecar container to the existing Pod <strong>big-corp-app</strong>. The new sidecar container has to run the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>/bin/sh -c tail -n+1 -f /var/log/big-corp-app.log
</span></span></code></pre></div><p>Use a volume mount named <strong>logs</strong> to make the file <strong>/var/log/big-corp-app.log</strong> available to the sidecar container.</p><blockquote><p>Donâ€™t modify the existing container.
Donâ€™t modify the path of the log file,both containers must access it at <strong>/var/log/big-corp-app.log</strong>.</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl>kubectl get pod big-corp-app -o yaml 
</span></span><span class=line><span class=cl><span class=c1>#</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>kind: Pod
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: big-corp-app
</span></span><span class=line><span class=cl>spec:
</span></span><span class=line><span class=cl>  containers:
</span></span><span class=line><span class=cl>  - name: big-corp-app image: busybox args: - /bin/sh - -c - &gt; <span class=nv>i</span><span class=o>=</span>0<span class=p>;</span> <span class=k>while</span> true<span class=p>;</span> <span class=k>do</span> <span class=nb>echo</span> <span class=s2>&#34;</span><span class=k>$(</span>date<span class=k>)</span><span class=s2> INFO </span><span class=nv>$i</span><span class=s2>&#34;</span> &gt;&gt; /var/log/big-corp-app.log<span class=p>;</span> <span class=nv>i</span><span class=o>=</span><span class=k>$((</span>i+1<span class=k>))</span><span class=p>;</span> sleep 1<span class=p>;</span> <span class=k>done</span> volumeMounts: - name: logs mountPath: /var/log
</span></span><span class=line><span class=cl>  - name: count-log-1 image: busybox args: <span class=o>[</span>/bin/sh, -c, <span class=s1>&#39;tail -n+1 -f /var/log/big-corp-app.log&#39;</span><span class=o>]</span> volumeMounts: - name: logs mountPath: /var/log
</span></span><span class=line><span class=cl>  volumes:
</span></span><span class=line><span class=cl>  - name: logs emptyDir: <span class=o>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#éªŒè¯ï¼š</span>
</span></span><span class=line><span class=cl>kubectl logs big-corp-app -c count-log-1
</span></span></code></pre></div><h2 id=16-task---è‹±æ–‡>16 Task - è‹±æ–‡
<a class=anchor href=#16-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Form the pod label <strong>name-cpu-loader</strong>,find pods running high CPU workloads and write the name of the pod consuming most CPU to the file <strong>/opt/KUTR00401/KURT00401.txt</strong>(which alredy exists).</p><p>æŸ¥çœ‹Podæ ‡ç­¾ä¸ºname=cpu-user-loader çš„CPUä½¿ç”¨ç‡å¹¶ä¸”æŠŠcpuä½¿ç”¨ç‡æœ€é«˜çš„podåç§°å†™å…¥/opt/KUTR00401/KUTR00401.txtæ–‡ä»¶é‡Œ</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl top pods -l <span class=nv>name</span><span class=o>=</span>name-cpu-loader --sort-by<span class=o>=</span>cpu
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;æ’åç¬¬ä¸€çš„podåç§°&#39;</span> &gt;&gt;/opt/KUTR00401/KUTR00401.txt
</span></span></code></pre></div><h2 id=17-task---è‹±æ–‡>17 Task - è‹±æ–‡
<a class=anchor href=#17-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Task
A Kubernetes worker node,named <strong>wk8s-node-0</strong> is in state <strong>NotReady</strong> .
Investigate why this is the case,and perform any appropriate steps to bring the node to a <strong>Ready</strong> state,ensuring that any changes are made permanent.</p><blockquote><p>Yon can <strong>ssh</strong> to teh failed node using:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh wk8s-node-o
</span></span></code></pre></div><p>You can assume elevated privileges on the node with the following command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo -i
</span></span></code></pre></div></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1>#åä¸ºwk8s-node-1 çš„èŠ‚ç‚¹å¤„äºNotReadyçŠ¶æ€ï¼Œå°†å…¶æ¢å¤æˆReadyçŠ¶æ€ï¼Œå¹¶ä¸”è®¾ç½®ä¸ºå¼€æœºè‡ªå¯</span>
</span></span><span class=line><span class=cl><span class=c1># è¿æ¥åˆ°NotReadyèŠ‚ç‚¹</span>
</span></span><span class=line><span class=cl>ssh wk8s-node-0
</span></span><span class=line><span class=cl><span class=c1>#è·å–æƒé™</span>
</span></span><span class=line><span class=cl>sudo -i
</span></span><span class=line><span class=cl><span class=c1># æŸ¥çœ‹æœåŠ¡æ˜¯å¦è¿è¡Œæ­£å¸¸</span>
</span></span><span class=line><span class=cl>systemctl status kubelet 
</span></span><span class=line><span class=cl><span class=c1>#å¦‚æœæœåŠ¡éæ­£å¸¸è¿è¡Œè¿›è¡Œæ¢å¤</span>
</span></span><span class=line><span class=cl>systemctl start kubelet
</span></span><span class=line><span class=cl><span class=c1>#è®¾ç½®å¼€æœºè‡ªå¯</span>
</span></span><span class=line><span class=cl>systemctl <span class=nb>enable</span> kubelet 
</span></span></code></pre></div><h2 id=19-task---è‹±æ–‡>19 Task - è‹±æ–‡
<a class=anchor href=#19-task---%e8%8b%b1%e6%96%87>#</a></h2><p>Set configuration context $ kubectl config use-context wk8s</p><p>configure the kubelet systemed managed service, on the node labelled with name=wk8s-node-1,to launch a pod containing a single container of image nginx named myservice automatically.</p><p>Any spec file requried should be placed in the /etc/kuberneteds/mainfests directory on the node</p><p>Hints:</p><p>You can ssh to the failed node using $ ssh wk8s-node-0</p><p>You can assume elevated privileges on the node with the following command $ sudo -i</p><h2 id=é™æ€podåˆ›å»ºæ–¹æ³•ä¸æ³¨æ„ç‚¹>é™æ€Podåˆ›å»ºæ–¹æ³•ä¸æ³¨æ„ç‚¹
<a class=anchor href=#%e9%9d%99%e6%80%81pod%e5%88%9b%e5%bb%ba%e6%96%b9%e6%b3%95%e4%b8%8e%e6%b3%a8%e6%84%8f%e7%82%b9>#</a></h2><p>Set configuration context $ kubectl config use-context wk8s</p><p>configure the kubelet systemed managed service, on the node labelled with name=wk8s-node-1,to launch a pod containing a single container of image nginx named myservice automatically.</p><p>Any spec file requried should be placed in the /etc/kuberneteds/mainfests directory on the node</p><p>Hints:</p><p>You can ssh to the failed node using $ ssh wk8s-node-0</p><p>You can assume elevated privileges on the node with the following command $ sudo -i</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl config use-context wk8s
</span></span><span class=line><span class=cl>kubectl get node -l<span class=o>=</span><span class=nv>name</span><span class=o>=</span>wk8s-node-0 -o wide
</span></span><span class=line><span class=cl><span class=c1># or</span>
</span></span><span class=line><span class=cl>kubectl get node -l <span class=nv>name</span><span class=o>=</span>wk8s-node-0 -o wide
</span></span><span class=line><span class=cl>sudo wk8s-node-0
</span></span><span class=line><span class=cl>sudo -i
</span></span><span class=line><span class=cl>systemctl status kubelet -l <span class=p>|</span>grep config <span class=c1>#æ‰¾åˆ°--configé…ç½®çš„æ–‡ä»¶è·¯å¾„</span>
</span></span><span class=line><span class=cl>cat /var/lib/kubelet/config.yaml <span class=p>|</span>grep staticPodPath <span class=c1># å¾—åˆ°/etc/kubernetes/manifests</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> /etc/kubernetes/manifests
</span></span><span class=line><span class=cl>kubectl run myservice --image<span class=o>=</span>nginx --dry-run<span class=o>=</span>client -o yaml &gt; myservice.yaml
</span></span><span class=line><span class=cl>kubectl get pod -A<span class=p>|</span>grep myservice <span class=c1>#å¯ä»¥å¾—åˆ°é™æ€Pod </span>
</span></span></code></pre></div><hr><p><a href=/cka/prepare-cka/>Â» å‡†å¤‡CKA</a></p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/poneding/blog/commit/5faa4f1be5d4525c49e513962394eae7c15fb6f2 title='æœ€åä¿®æ”¹è€… poneding | 2024/06/13' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt>
<span>2024/06/13</span></a></div><div><a class="flex align-center" href=https://github.com/poneding/blog/edit/master/content/cka/001.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt>
<span>ç¼–è¾‘æœ¬é¡µ</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=poneding/blog data-repo-id=R_kgDOMITIHg data-category=General data-category-id=DIC_kwDOMITIHs4CgB4x data-mapping=url data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#01-task---è‹±æ–‡>01 Task - è‹±æ–‡</a></li><li><a href=#02-task---è‹±æ–‡>02 Task - è‹±æ–‡</a></li><li><a href=#03-task---è‹±æ–‡>03 Task - è‹±æ–‡</a></li><li><a href=#04-task---ä¸­æ–‡>04 Task - ä¸­æ–‡</a></li><li><a href=#05-task---è‹±æ–‡>05 Task - è‹±æ–‡</a></li><li><a href=#06-task---è‹±æ–‡>06 Task - è‹±æ–‡</a></li><li><a href=#07-task---è‹±æ–‡>07 Task - è‹±æ–‡</a></li><li><a href=#08-task---è‹±æ–‡>08 Task - è‹±æ–‡</a></li><li><a href=#09-task---è‹±æ–‡>09 Task - è‹±æ–‡</a></li><li><a href=#10-task---è‹±æ–‡>10 Task - è‹±æ–‡</a></li><li><a href=#11-task---è‹±æ–‡>11 Task - è‹±æ–‡</a></li><li><a href=#12-task---è‹±æ–‡>12 Task - è‹±æ–‡</a></li><li><a href=#13-task---è‹±æ–‡>13 Task - è‹±æ–‡</a></li><li><a href=#14-task---è‹±æ–‡>14 Task - è‹±æ–‡</a></li><li><a href=#15-task---è‹±æ–‡>15 Task - è‹±æ–‡</a></li><li><a href=#16-task---è‹±æ–‡>16 Task - è‹±æ–‡</a></li><li><a href=#17-task---è‹±æ–‡>17 Task - è‹±æ–‡</a></li><li><a href=#19-task---è‹±æ–‡>19 Task - è‹±æ–‡</a></li><li><a href=#é™æ€podåˆ›å»ºæ–¹æ³•ä¸æ³¨æ„ç‚¹>é™æ€Podåˆ›å»ºæ–¹æ³•ä¸æ³¨æ„ç‚¹</a></li></ul></nav></div></aside></main></body></html>